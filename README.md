# Financial-Analysis-Pipeline-with-ML-and-Portfolio-Construction-CodeBase
This repository contains Python scripts and Jupyter Notebooks for financial analysis, integrating data retrieval, machine learning models, and portfolio construction. It includes text embedding using transformers, rolling-window analysis, and visualisation of portfolio performance. Ideal for finance and ML research.

# üöÄ Comprehensive Data Processing and Machine Learning Pipeline for Financial Analysis üìä

Welcome to the **Comprehensive Data Processing and Machine Learning Pipeline for Financial Analysis** repository! This project provides a robust and versatile pipeline designed for financial data analysis, featuring tools for data processing, feature engineering, machine learning, and performance evaluation. The codebase is adaptable to local machines and cloud environments like Google Colab.

## üìÇ Repository Contents

- **`comprehensive_data_processing_and_machine_learning_pipeline_for_financial_analysis.py`**: The main Python script for the complete pipeline.
- **`Comprehensive_Data_Processing_and_Machine_Learning_Pipeline_for_Financial_Analysis.ipynb`**: Jupyter Notebook version optimized for Google Colab.

## ‚ú® Features

- üõ†Ô∏è **Data Retrieval & Processing**: Seamlessly fetch and process financial data.
- üéõÔ∏è **Feature Engineering & Model Training**: Utilize advanced techniques to prepare your data and train state-of-the-art models.
- üìà **Performance Evaluation**: Comprehensive metrics and visualizations to analyze model performance.
- üåê **Local & Cloud Compatibility**: You can easily run the pipeline on your local machine or in the cloud using Google Colab.

## üîß Requirements

- üêç **Python**: 3.10.12 or above
- üì¶ Required Python packages:
  - `numpy` (latest)
  - `pandas` (latest)
  - `scipy` (latest)
  - `matplotlib` (latest)
  - `seaborn` (latest)
  - `torch` (latest)
  - `transformers` (latest)
  - `datasets` (latest)
  - `wrds` (latest)
  - `accelerate` (latest)

## ‚öôÔ∏è Setup Instructions

### 1Ô∏è‚É£ Clone the Repository

To get started, clone this repository to your local machine:

```bash
git clone https://github.com/your-username/your-repository-name.git
cd your-repository-name
```

## 2Ô∏è‚É£ Running the `.py` File Locally

### Install Dependencies üì•:

Ensure you have Python 3.10.12 or above. Install the necessary packages:

```python
pip install wrds
pip install --upgrade numpy scipy pyarrow pandas datasets transformers
pip install accelerate -U
```

### Run the Python Script üñ•Ô∏è:
Execute the main script with:

```bash
python comprehensive_data_processing_and_machine_learning_pipeline_for_financial_analysis.py
```

## 3Ô∏è‚É£ Running the .ipynb File Locally

### Install Jupyter Notebook üìì:
If you don‚Äôt have Jupyter Notebook installed:

```bash
pip install notebook
```

### Launch Jupyter Notebook üöÄ:
Start Jupyter Notebook:

```bash
jupyter notebook
```

### Open the Notebook üìÇ:
Navigate to the `Comprehensive_Data_Processing_and_Machine_Learning_Pipeline_for_Financial_Analysis.ipynb` file and open it.

---

## 4Ô∏è‚É£ Running on Google Colab

### Open Google Colab üåê:
Head over to [Google Colab](https://colab.research.google.com/).

### Upload the Notebook üì§:
- Click on `File > Upload Notebook`.
- Upload `Comprehensive_Data_Processing_and_Machine_Learning_Pipeline_for_Financial_Analysis.ipynb`.

### Install Required Libraries ‚öôÔ∏è:
In the first cell, install the necessary packages:

```python
!pip install wrds
!pip install --upgrade numpy scipy pyarrow pandas datasets transformers
!pip install accelerate -U
```

### Run the Notebook ‚ñ∂Ô∏è:
Execute each cell to run the entire pipeline.

---

## üõ†Ô∏è Hardware Configuration

The project has been tested on the following hardware configuration:

- **GPU**: NVIDIA L4
- **CUDA Version**: 12.2
- **RAM**: 53.0 GB
- **GPU RAM**: 22.5 GB
- **Disk**: 78.2 GB

---

## üìë Documentation

Detailed documentation for the project can be found in the `docs` folder. This includes descriptions of each function, class, and workflow within the project.
